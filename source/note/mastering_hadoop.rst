《精通Hadoop》
=================

.. toctree::
   :maxdepth: 2

   mastering_hadoop/chapter_summary
   mastering_hadoop/relevant_knowledge

知识点
^^^^^^^^^^^^^^^^^^^^^^^
- HDFS可能由成百上千的服务器所构成，所以硬件错误是常态而不是异常。错误检测和快速、自动的恢复是 *HDFS* 最核心的架构目标
- HDFS上的一个典型文件大小一般都在G字节至T字节。因此，HDFS被调节以支持大文件存储。一个单一的HDFS实例应该能支撑数以千万计的文件。
- HDFS应用需要一个“一次写入多次读取”的文件访问模型。
- 一个应用请求的计算，离它操作的数据越近就越高效，在数据达到海量级别的时候更是如此。将计算移动到数据附近，比之将数据移动到应用所在显然更好。HDFS为应用提供了将它们自己移动到数据附近的接口。

相关名词
^^^^^^^^^^^^^^^^^^^^^^^
- **无锁高并发队列** : 比如 `HBase` 中的 **LMAX Disrutpor RingBuffer** 。


求知的冲动
^^^^^^^^^^^^^^^^^^^^^^^
- 有时间的话，去了解一下 **robots.txt协议** 。
- **LSM树** : 一种NOSQL系统广泛使用的结构。
- 了解HBase的 **Write Ahead Log (WAL)** 的工作机制。它是一种高并发、持久化的日志保存与回放机制。

  - 有时间也了解一下 **HBase** 的工作机制，特别是其中的 **Region Server** 。

- 其他

见闻
^^^^^^^^^^^^^^^^^^^^^^^
- 搜索引擎曾经遇见过这样的问题： `垃圾虫们就会在网站上加入许多相关或不相关的关键词，从而欺骗搜索引擎使它们出现在几乎所有的查询结果中。`

  而Google当时使用算法 **PageRank** 解决了这个问题。 **PageRank** 通过分析指向某一特定页面的链接的质量和数量，阻碍了这种欺骗行为，它的出发点是重要的页面会有更多的入站链接。

- Nutch搭配其他诸如Lucene和Solr这样的索引技术，为构建搜索引擎提供了必要的组件，但还不能满足互联网级别规模的需要。 **MapReduce** 和 **分布式文件系统** 概念解决了Nutch遇到的一些扩展性问题。最后Hadoop的出现，彻底解决这个问题。
- HBase设计之初的想法：以查询性能的下降来换取更新性能的提升。更新操作先在内存，然后批量进入Hadoop。


疑问
^^^^^^^^^^^^^^^^^^^^^^^
- **Kerberos安全体系** 的介绍中， **用户** 与 **Authentication Server**  、 **Ticket Granting Server** 的交互，为什么不一次性完成？
- **Hadoop** 的 `安全特性` 中， **访问控制列表** 是如何工作的？
- 用户与 **Authentication Server** 、 **与Ticket Granting Server** 的交互，为什么不一次性完成？
