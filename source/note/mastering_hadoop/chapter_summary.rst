章节总结
================================
按照章节，整理本书中的内容。

第一章 Hadoop2.x
^^^^^^^^^^^^^^^^^^^^^^^^^^^
知识点
##############
- 在网络爬虫领域，垃圾虫们就会在网站上加入许多相关或不相关的关键词，从而欺骗搜索引擎使它们出现在几乎所有的查询结果中。为此 *Google* 设计了 ``PageRank`` 算法，PageRank通过分析指向某一特定页面的链接的质量和数量，阻碍了这种欺骗行为，它的出发点是重要的页面会有更多的入站链接。
- **机器人排除标准** （Robot Exclusion Standard） ，即 **robots.txt协议** ，是一个建议爬虫如何抓取网页的忠告性协议。它是一个放在网页服务器根目录下的文件，用来建议爬虫应该或者不应该抓取某个公共网页或者目录。作为一个有礼貌的爬虫，其中一个特征就是遵守放置在robots.txt文件内的建议。
- **Kerberos认证系统**
- **访问控制列表** （Access Control Lists， ``ACL`` ）
- Hadoop 1.X采用集中式作业流控制，然而集中式系统由于其负载的单点问题，很难实现扩展。一旦JobTracker（作业跟踪器）出现故障，系统中所有的作业都必须重新启动，这对整个集中式组件造成了极大压力。按照这种模式， Hadoop很难与其他类型的集群进行集成。
- Hadoop 1.X版本将所有HDFS目录和文件的元数据存储到一个NameNode单点，这样对该节点 **容错性** 造成了障碍。即便后来加入了对该节点的 **冷备份** ，却因为不是 **热备份** ，所以故障切换时间和恢复时间较长，集群可用性会受到影响。

文件追加特性
  它让用户在执行HBase的时候不再担心数据丢失的风险。

  最初的Hadoop提供的是一种一次写入多次读取（write-once-read-many-times）的模式，且当文件被写入时，没有人能读取文件的内容。任何程序在写HDFS文件的过程中，当写操作失败或者程序崩溃时，都必须重写这个文件的全部内容。

  但是HBase这样的在线系统去不是这样的。如果日志文件写失败，事务（transaction）操作就不能再被执行，从而导致数据的丢失。如果能够根据日志内容重新执行事务操作，那数据就不会丢失。文件追加功能使HBase和其他需要事务操作的应用能够在HDFS上执行，从而降低了这一风险。

  HBase的 **Write Ahead Log (WAL)** 强烈依赖Hadoop的“文件追加”功能。

安全特性
  进行数据隔离、数据认证以及Hadoop作业和数据的授权

**MapReduce** 不适合迭代类计算
  因为MapReduce一次执行的过程中，设计多次磁盘读写。对于迭代任务，这样的开销会进行多次，明显降低了效率。

**MapReduce** 不适合实时性比较高的任务
  因为 `MapReduce` 的启动时间比较长，对于批处理的任务，这个问题并不算大。但是对于实时性比较高的任务，其任务时间长的缺点就很不合适了。这里提到的时间长是相对 **时延** 要求较高的场景，实际上Hadoop、MapReduce一次任务执行的时间可能是几分钟而已。

**节点** 与 **容器** 的不同
  节点倾向于物理层的描述；容器倾向逻辑层的描述。

Hadoop 1.x 到 2.x 从架构上的变化
  |hadoop_framework_change_1x_to_2x|

  **Resource Manager** （ **RM** 、资源管理器）：每个集群都有一个RM，它主要用来跟踪资源的使用情况，同时也负责资源的分配和解决集群中的资源竞争问题。 

  **Application Master** （ **AM** ）：负责一个作业的调度和执行工作，而且每个应用有一个单独的AM实例。AM向RM请求资源，然后使用资源执行作业，并处理作业执行中可能出现的错误。

  **NodeManager** （ **NM** 、节点管理器）：是集群中每个节点上执行的一个后台进程，它协助RM做节点的本地资源管理工作。 NM承担容器的管理功能，例如启动和释放容器，跟踪本地资源的使用，以及错误通知工作。 NM发送心跳信息给RM，而RM通过汇总所有的NM的心跳信息从而了解整个系统的状态。

  **Job** （作业）：是直接向RM提交的， RM基于集群的资源可用情况调度作业执行。作业的基本信息保存在可靠的存储系统中，这样当RM崩溃后很容易恢复作业重新执行。在一个作业被调度执行后， RM在集群的某个节点上分配一个容器给该作业，作为这个作业的AM。

  **容器** ：这是一个与节点绑定的资源抽象概念，例如，一个节点上的2个CPU和4 GB内存可以作为一个容器。

  这个运行过程可以这样描述：

  | 一般情况下在集群中指定一台机器以守护进程（daemon）的方式运行RM， RM维护着整个集群的全局状态和资源分配情况。由于拥有全局的信息， RM可以根据集群的资源使用率做出公平的资源配置。当收到资源请求时， RM动态地分配一个容器（container）给请求方。
  | 然后， AM就接管了这个作业的后续处理，包括请求资源、管理任务执行、优化和处理任务的异常。 AM可以用任何语言编写，并且不同版本的AM可以独立地运行在同一个集群里面。
  | AM请求的资源明确了本地化信息和期望的资源类型，RM会基于资源分配策略和当前可用资源的情况尽力满足AM的要求。当AM获取到一个容器时，它能在容器内执行自己的应用程序，并且可以自由地和这个容器通信，而RM并不知道这些通信的存在。

Hadoop 2.X中对存储层的增强
  **NameNode** 其实是Hadoop的一个目录服务，它包含着整个集群存储的文件的元数据。区别于1.X，2.X使用了 *NameNode* 的 **热备份** ，它能够提供无数据丢失且不间断的NameNode服务，并且自动故障切换也比较容易实现。

  热备份的关键在于维护它的数据尽可能与主NameNode节点保持一致，可以通过读取主NameNode的写日志文件并在备份节点上执行来实现，并且延时也是非常低的。写日志文件的共享可以使用以下两种方法来实现。

  - 在主NameNode和从NameNode节点间使用共享的网络文件系统（Network File System，NFS）存储目录：主NameNode往共享目录中写入日志，而从NameNode监听这个共享目录的变更消息，然后拉取这些变更。
  - 使用一组 ``JournalNode`` （quorum of Journal Nodes）：主NameNode将写日志发送到部分JournalNode以记录信息，而从NameNode持续监听这些JournalNode，从而更新和同步主NameNode的状态。

  ``ZooKeeper`` 等高可用的监听服务可以用来跟踪NameNode的故障，并且可以触发故障切换的流程，使从NameNode节点提升为主节点。

  下图展示了一种使用基于有效配额的存储系统的高可用实现框架。DateNode需要同时发送数据块报告信息（block report）到主从两个NameNode。

  |hadoop_framework_about_strength_of_storage|

HDFS联合
  该功能允许多个HDFS命名空间使用相同的底层存储设备，且联合的NameNode节点提供了文件系统层面的隔离功能。

HDFS快照
  HDFS的快照仅在NameNode上实现，它不会涉及数据从一个数据节点复制到另一个数据节点，而仅仅是复制了块列表以及文件的大小。生成一个快照的操作几乎是瞬间完成的，它不会影响NameNode节点的性能。

  快照（snapshot）是文件系统的整体或部分目录在某个时间点的只读镜像（image），通常是为了以下三个原因：

  - 防止用户的错误操作导致的数据损坏或丢失
  - 备份
  - 容灾

.. |hadoop_framework_change_1x_to_2x| image:: /images/hadoop/hadoop_framework_change_1x_to_2x.png
   :width: 100%
.. |hadoop_framework_about_strength_of_storage| image:: /images/hadoop/hadoop_framework_about_strength_of_storage.png
   :width: 100%

疑惑
##########################
- **JournalNode** 是如何工作的？为什么需要有多个？

第二章 MapReduce 进阶
^^^^^^^^^^^^^^^^^^^^^^^^^^^
- 对于 ``2.6`` 节，我没有看懂，需要回头再看一下。
